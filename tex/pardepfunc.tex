\par{

\subsection{Partial Dependence Function}

It is useful to have a coherent method of measuring the importance a specific variable $X_j$ has on the output $Y$. 
Since partial dependence plots usually only depict the relationship between two variables, we follow Klusowski (2019) by introducing a conditional partial dependence function. 
Recall that we assume $Y_i = m(\mathbf{X}_i) + \epsilon_i$. 
The idea behind the conditional partial dependence function is to look at the influence of one specific $X_j$ while ignoring the others. 
For this let 

\begin{align}
    \bar{F}_j(x_j; \mathbf{t}) = E [Y \ | \ \mathbf{X} \in \mathbf{t}, X_j = x_j] \label{pardepfunc_f}
\end{align}

where $\bar{F}_j(x_j; \mathbf{t})$ is the partial dependence function for variable $j$ conditional on being in node $\mathbf{t}$. 
One can also think of () as a solution to a least squares approximation of $m(\mathbf{X})$ as a function of only $X_j$ within node $\mathbf{t}$.
For later purposes it will be beneficial to additionally define the mean centered partial dependence function 

\begin{align}
    \bar{G}_j(x_j; \mathbf{t}) &= \bar{F}_j(x_j; \mathbf{t}) - E [Y \ | \ \mathbf{X} \in \mathbf{t}] \nonumber \\
    &= E [Y \ | \ \mathbf{X} \in \mathbf{t}, X_j = x_j] - E [Y \ | \ \mathbf{X} \in \mathbf{t}] \label{pardepfunc_g}
\end{align}

which is the partial dependence function demeaned by the average of all observation within the respective node. \\

This concept now allows us to reformulate our definition of strong and weak variables. Since 
}